{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aPWBhUxTeb5B"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "# # LSTMおよび線形予測による歩行者軌跡予測\n",
        "# - 観測: 20フレーム(2秒間)の歩行者の座標\n",
        "# - 予測: 観測後30フレーム(3秒間)の歩行者の軌跡\n",
        "# - モデル: TrajectoryLSTM (絶対座標を学習)，TrajectoryLSTM_Relative (相対座標を学習)，LinearPredictionModel (線形予測)\n",
        "# - 指標: 平均距離誤差(ADE) / 終点距離誤差(FDE)\n",
        "\n",
        "#!pip -q install torch torchvision torchaudio matplotlib numpy pandas\n",
        "\n",
        "# %%\n",
        "import math, random, os, sys, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Device: cpu の場合，ランタイム→ランタイムのタイプを変更→T4 GPUに切り替える"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz5CnWH_AUpT"
      },
      "outputs": [],
      "source": [
        "# ドライブマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VbeXq1DemfH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# merged_human_traj.csvまでのパスを入れれば動きます．マイドライブ直下の場合は以下で動くはず\n",
        "csv_path = \"/content/drive/MyDrive/merged_human_traj.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()\n",
        "\n",
        "# マウントできていれば左に並んでいる中のフォルダマークをクリックすると\"drive\"というフォルダ(ディレクトリ)が見える\n",
        "# \"drive → Mydrive →...→ ~.csv\"という感じにファイルを見つけて右クリックでパス取得可能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hsohj-vIgQPk"
      },
      "outputs": [],
      "source": [
        "class TrajectoryDataset(Dataset):\n",
        "    \"\"\"\n",
        "    各 traj_id から連続した obs_len+pred_len のウィンドウ切り出し\n",
        "    modeはどこを切り出すか，xのみyのみ，もしくはall\n",
        "    lenは人数を出力\n",
        "\n",
        "    output：\n",
        "    obs → (人数, 20, 1 or 2)\n",
        "    fut → (人数, 30, 1 or 2)\n",
        "    \"\"\"\n",
        "    def __init__(self, df, obs_len=20, pred_len=30, stride=1, normalize=False, mode='all'):\n",
        "\n",
        "        self.obs_len = obs_len\n",
        "        self.pred_len = pred_len\n",
        "        self.seq_len = obs_len + pred_len\n",
        "        self.normalize = normalize\n",
        "        self.mode = mode\n",
        "\n",
        "        self.seqs = []\n",
        "        for tid, g in df.groupby(\"traj_id\"):\n",
        "            g = g.sort_values(\"frame\")\n",
        "\n",
        "            if mode == 'x':\n",
        "                xy = g[[\"x\"]].to_numpy(dtype=np.float32) # x座標のみ取り出す\n",
        "            elif mode == 'y':\n",
        "                xy = g[[\"y\"]].to_numpy(dtype=np.float32) # y座標のみ取り出す\n",
        "            elif mode == 'all':\n",
        "                xy = g[[\"x\",\"y\"]].to_numpy(dtype=np.float32)  # x,y座標ともに取り出す\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid mode: {mode}\")\n",
        "\n",
        "            if len(xy) < self.seq_len:\n",
        "                continue\n",
        "\n",
        "            # ウィンドウ切り出し\n",
        "            for s in range(0, len(xy)-self.seq_len+1, stride):\n",
        "                subseq = xy[s:s+self.seq_len]\n",
        "                self.seqs.append(subseq)\n",
        "\n",
        "        # shapeを揃える (人数, 50, 次元)\n",
        "        if len(self.seqs) > 0:\n",
        "            self.seqs = np.stack(self.seqs, axis=0)\n",
        "        else:\n",
        "            D = 1 if mode in ['x','y'] else 2\n",
        "            self.seqs = np.zeros((0, self.seq_len, D), dtype=np.float32)\n",
        "\n",
        "        D = self.seqs.shape[2]\n",
        "\n",
        "        # 正規化（全データ一括）\n",
        "        if self.normalize and len(self.seqs) > 0:\n",
        "            # self.normalizeがTrueの時，正規化に必要な値を取得\n",
        "            self.mean = self.seqs[:,:self.obs_len,:].reshape(-1,D).mean(axis=0, keepdims=True)\n",
        "            self.std  = self.seqs[:,:self.obs_len,:].reshape(-1,D).std(axis=0, keepdims=True) + 1e-6\n",
        "        else:\n",
        "            self.mean = np.zeros((1,D), dtype=np.float32)\n",
        "            self.std  = np.ones((1,D), dtype=np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.seqs[idx].copy()\n",
        "        seq = (seq - self.mean) / self.std\n",
        "\n",
        "        obs = seq[:self.obs_len]          # 座標（正規化後）\n",
        "        fut = seq[self.obs_len:]          # 座標（正規化後）\n",
        "\n",
        "        return {\n",
        "            \"obs\": torch.from_numpy(obs).float(),         # 入力用\n",
        "            \"fut\": torch.from_numpy(fut).float(),         # 予測評価，教師用\n",
        "        }\n",
        "\n",
        "\n",
        "#データセットアップ用\n",
        "def setup_data(ped_data, obs_len=20, pred_len=30, mode='x', max_samples=10000):\n",
        "    dataset = TrajectoryDataset(ped_data, obs_len=obs_len, pred_len=pred_len, stride=1, normalize=True, mode=mode)\n",
        "\n",
        "    n = len(dataset)\n",
        "    if n > max_samples:\n",
        "        print(f\"Dataset over {max_samples}(now {n} samples), randomly subsampling to {max_samples}.\")\n",
        "        # 再現性のためseed固定\n",
        "        random.seed(0) # ※編集禁止\n",
        "        indices = random.sample(range(n), max_samples)\n",
        "        dataset = torch.utils.data.Subset(dataset, indices)\n",
        "        n = max_samples\n",
        "    n_train = int(n*0.8)\n",
        "    n_val = n - n_train\n",
        "    print(f\"Dataset size: total={n}  train={n_train}  val={n_val}\")\n",
        "    train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
        "    return train_set, val_set\n",
        "\n",
        "#評価指標計算用\n",
        "def ade(pred, gt):\n",
        "    \"\"\"入力は (人数, フレーム数, 次元)を想定\"\"\"\n",
        "    # 平均距離誤差（Average Displacement Error）を計算\n",
        "    return torch.norm(pred - gt, dim=2).mean()\n",
        "\n",
        "\n",
        "def fde(pred, gt):\n",
        "    \"\"\"入力は (人数, フレーム数, 次元)を想定\"\"\"\n",
        "    # 終点距離誤差（Final Displacement Error）を計算\n",
        "    return torch.norm(pred[:,-1,:] - gt[:,-1,:], dim=1).mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzUFKcztjcgM"
      },
      "outputs": [],
      "source": [
        "# 線形予測モデル\n",
        "class LinearPredictionModel(nn.Module):\n",
        "    def __init__(self, obs_len=20, fut_len=30):\n",
        "        super().__init__()\n",
        "        self.obs_len = obs_len\n",
        "        self.fut_len = fut_len\n",
        "\n",
        "    def forward(self, obs_abs):\n",
        "        #線形予測を組み立てるのは以下の部分\n",
        "        B, O, D = obs_abs.shape\n",
        "        last_movement = obs_abs[:, -1, :] - obs_abs[:, -2, :]  # 最後から最後から２番目を引く\n",
        "        preds = []\n",
        "        for t in range(self.fut_len):\n",
        "            pred = obs_abs[:, -1, :] + last_movement * (t+1)  # 最後のステップに，フレーム数*最後の動きを足していく\n",
        "            preds.append(pred[:, np.newaxis, :])\n",
        "        preds = torch.cat(preds, dim=1)  # (B, fut_len, D)\n",
        "        return preds\n",
        "\n",
        "\n",
        "# モデル定義\n",
        "#絶対座標で学習するモデル\n",
        "class TrajectoryLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    input: obs_abs フレームの絶対座標 (バッチサイズ, 入力の長さ, 次元)\n",
        "\n",
        "    output: pred_abs フレーム先の絶対座標 (バッチサイズ, 予測の長さ, 次元)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=1, hidden_size=128, num_layers=1, pred_len=30):\n",
        "        super().__init__()\n",
        "        self.pred_len = pred_len\n",
        "        self.input_size = input_size\n",
        "        self.encoder = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.head = nn.Linear(hidden_size, pred_len * input_size)\n",
        "\n",
        "    def forward(self, obs_abs):               # (B, obs_len, D)\n",
        "        _, (h, _) = self.encoder(obs_abs)     # h: (num_layers, B, H)\n",
        "        h_last = h[-1]                        # (B, H)\n",
        "        out = self.head(h_last)               # (B, pred_len*D)\n",
        "        pred_abs = out.view(-1, self.pred_len, self.input_size)  # (B, pred_len, D)\n",
        "        return pred_abs\n",
        "\n",
        "\n",
        "#相対座標を生成して学習するモデル\n",
        "class TrajectoryLSTM_Relative(nn.Module):\n",
        "    \"\"\"\n",
        "    input: obs_abs フレームの絶対座標 (バッチサイズ, 入力の長さ, 次元)\n",
        "\n",
        "    output: pred_abs フレーム先の絶対座標 (バッチサイズ, 予測の長さ, 次元)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=1, hidden_size=128, num_layers=1, pred_len=30):\n",
        "        super().__init__()\n",
        "        self.pred_len = pred_len\n",
        "        self.input_size = input_size\n",
        "        self.encoder = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.head = nn.Linear(hidden_size, pred_len * input_size)\n",
        "\n",
        "    def forward(self, obs_abs):               # (B, obs_len, D)\n",
        "        # 相対座標に変換\n",
        "        obs_start = obs_abs[:,0:1,:]          # (B, 1, D)\n",
        "        obs_rel = obs_abs - obs_start      # (B, obs_len, D)\n",
        "\n",
        "        _, (h, _) = self.encoder(obs_rel)     # h: (num_layers, B, H)\n",
        "        h_last = h[-1]                        # (B, H)\n",
        "        out = self.head(h_last)               # (B, pred_len*D)\n",
        "        pred_rel = out.view(-1, self.pred_len, self.input_size)  # (B, pred_len, D)\n",
        "\n",
        "        # 絶対座標に戻す\n",
        "        pred_abs = pred_rel + obs_start       # (B, pred_len, D)\n",
        "        return pred_abs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyaGuNMijC3a"
      },
      "outputs": [],
      "source": [
        "# 学習用ループ\n",
        "def train_model(ped_data, model_type='absolute', data_mode='x', input_size=1, epochs=50, batch_size=256, lr=0.001, hidden_size=128, obs_len=20, pred_len=30):\n",
        "    train_set, val_set = setup_data(ped_data, obs_len=obs_len, pred_len=pred_len, mode=data_mode)\n",
        "    if model_type == 'absolute':\n",
        "        model = TrajectoryLSTM(hidden_size=hidden_size, input_size=input_size, pred_len=pred_len).to(device)\n",
        "    elif model_type == 'relative':\n",
        "        model = TrajectoryLSTM_Relative(hidden_size=hidden_size, input_size=input_size, pred_len=pred_len).to(device)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid model_type: {model_type}\")\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "    print(f\"Training on {len(train_set)} samples, validating on {len(val_set)} samples.\")\n",
        "    print(f\"Input mode: {data_mode}, obs_len={obs_len}, pred_len={pred_len}\")\n",
        "    print(f\"Training model with {sum(p.numel() for p in model.parameters() if p.requires_grad)} parameters.\")\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    history = []\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        tr_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            obs = batch[\"obs\"].to(device)\n",
        "            fut = batch[\"fut\"].to(device)\n",
        "\n",
        "            pred_abs = model(obs)\n",
        "\n",
        "            loss = ade(pred_abs, fut)  # シンプルにADEを損失に\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            tr_loss += loss.item()\n",
        "\n",
        "        # 検証\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_ade, val_fde = 0.0, 0.0\n",
        "            count = 0\n",
        "            for batch in val_loader:\n",
        "                obs = batch[\"obs\"].to(device)\n",
        "                fut = batch[\"fut\"].to(device)\n",
        "                pred_abs = model(obs)\n",
        "                val_ade += ade(pred_abs, fut).item() * obs.size(0)\n",
        "                val_fde += fde(pred_abs, fut).item() * obs.size(0)\n",
        "                count += obs.size(0)\n",
        "            val_ade /= count\n",
        "            val_fde /= count\n",
        "\n",
        "        history.append((ep, tr_loss/len(train_loader), val_ade, val_fde))\n",
        "        print(f\"[Epoch {ep:02d}] train_loss={tr_loss/len(train_loader):.4f}  val_ADE={val_ade:.4f}  val_FDE={val_fde:.4f}\")\n",
        "\n",
        "        if val_ade < best_val:\n",
        "            best_val = val_ade\n",
        "            torch.save({\"model\": model.state_dict()}, f\"/content/traj_lstm_best_{data_mode}_{model_type}.pth\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "#各モードテスト用(allの場合も可能)\n",
        "#x,yを別々に評価したい場合などにも利用可能\n",
        "def test_each_mode(model, ped_data, mode='x', obs_len=20, pred_len=30):\n",
        "    print(f\"--- Testing mode: {mode} ---\")\n",
        "    _, test_set = setup_data(ped_data, mode=mode, obs_len=obs_len, pred_len=pred_len, max_samples=10000)\n",
        "    test_loader = DataLoader(test_set, batch_size=1, shuffle=False, drop_last=False)\n",
        "    model.eval()\n",
        "    ade_lstm, fde_lstm = 0.0, 0.0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            obs = batch[\"obs\"].to(device)\n",
        "            fut = batch[\"fut\"].to(device)\n",
        "\n",
        "            pred_abs = model(obs)\n",
        "            ade_lstm += ade(pred_abs, fut).item() * obs.size(0)\n",
        "            fde_lstm += fde(pred_abs, fut).item() * obs.size(0)\n",
        "\n",
        "            count += obs.size(0)\n",
        "    ade_lstm /= count\n",
        "    fde_lstm /= count\n",
        "    print(f\"RESULT: ADE={ade_lstm:.4f}  FDE={fde_lstm:.4f}  Mode={mode}\")\n",
        "    return (ade_lstm, fde_lstm)\n",
        "\n",
        "\n",
        "#複数モデルテスト用\n",
        "def test_separate_modes(model_x, model_y, ped_data, obs_len=20, pred_len=30):\n",
        "    print(\"--- Testing separate modes ---\")\n",
        "\n",
        "    model_x.eval()\n",
        "    model_y.eval()\n",
        "    _, test_set = setup_data(ped_data, mode='all', obs_len=obs_len, pred_len=pred_len, max_samples=10000)\n",
        "    test_loader = DataLoader(test_set, batch_size=1, shuffle=False, drop_last=False)\n",
        "    ade_lstm, fde_lstm = 0.0, 0.0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            obs = batch[\"obs\"].to(device)\n",
        "            fut = batch[\"fut\"].to(device)\n",
        "\n",
        "            pred_x = model_x(obs[:,:,0:1])\n",
        "            pred_y = model_y(obs[:,:,1:2])\n",
        "            pred_abs = torch.cat([pred_x, pred_y], dim=2)\n",
        "\n",
        "            ade_lstm += ade(pred_abs, fut).item() * obs.size(0)\n",
        "            fde_lstm += fde(pred_abs, fut).item() * obs.size(0)\n",
        "\n",
        "            count += obs.size(0)\n",
        "    ade_lstm /= count\n",
        "    fde_lstm /= count\n",
        "    print(f\"RESULT: ADE={ade_lstm:.4f}  FDE={fde_lstm:.4f}  Mode=separate\")\n",
        "    return (ade_lstm, fde_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bK4MsH6ZuiVW"
      },
      "outputs": [],
      "source": [
        "# 線形モデルを用いて予測する\n",
        "linear_model = LinearPredictionModel()\n",
        "result = test_each_mode(linear_model, df, mode='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGlDSfI5plmJ"
      },
      "outputs": [],
      "source": [
        "# LSTMモデルでx,y別々に学習して予測する\n",
        "# 入力座標は絶対値\n",
        "model_x, hist_x = train_model(df, model_type='absolute', data_mode='x', input_size=1, epochs=50, batch_size=256, lr=1e-3, hidden_size=128)\n",
        "model_y, hist_y = train_model(df, model_type='absolute', data_mode='y', input_size=1, epochs=50, batch_size=256, lr=1e-3, hidden_size=128)\n",
        "result = test_separate_modes(model_x, model_y, df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1UXPA0vHfOc"
      },
      "outputs": [],
      "source": [
        "# LSTMモデルでx,yの2次元で学習して予測する\n",
        "# 入力座標は絶対値\n",
        "model, hist = train_model(df, model_type='absolute', data_mode='all', input_size=2, epochs=50, batch_size=256, lr=1e-3, hidden_size=128)\n",
        "result = test_each_mode(model, df, mode='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBjtcCbU2JfH"
      },
      "outputs": [],
      "source": [
        "# LSTMモデルでx,y別々に学習して予測する\n",
        "# 入力座標は相対値\n",
        "model_x_relative, hist_x_relative = train_model(df, model_type='relative', data_mode='x', input_size=1, epochs=50, batch_size=256, lr=1e-3, hidden_size=128)\n",
        "model_y_relative, hist_y_relative = train_model(df, model_type='relative', data_mode='y', input_size=1, epochs=50, batch_size=256, lr=1e-3, hidden_size=128)\n",
        "result = test_separate_modes(model_x_relative, model_y_relative, df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDgKdYh72GiE"
      },
      "outputs": [],
      "source": [
        "# LSTMモデルでx,yの2次元で学習して予測する\n",
        "# 入力座標は相対値\n",
        "model_relative, hist_relative = train_model(df, model_type='relative', data_mode='all', input_size=2, epochs=50, batch_size=256, lr=1e-3, hidden_size=128)\n",
        "result = test_each_mode(model_relative, df, mode='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKp7y52MqmIe"
      },
      "outputs": [],
      "source": [
        "# ロスカーブの可視化\n",
        "ep, tr, va, vf = zip(*hist) # histを見たいモデルのhistに切り替え可能\n",
        "# ep, tr, va, vf = zip(*hist_relative) # 例えば\n",
        "plt.figure()\n",
        "plt.plot(ep, tr, label=\"train_loss(ADE)\", color='blue')\n",
        "plt.plot(ep, va, label=\"val_ADE\", color='r')\n",
        "plt.plot(ep, vf, label=\"val_FDE\", color='g')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.legend()\n",
        "plt.title(\"Training History\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
